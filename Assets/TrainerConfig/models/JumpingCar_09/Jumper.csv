Steps,Policy/Entropy,Environment/Episode Length,High Score,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,0.6102426,16.649488175079423,8.0,-0.5174403,-0.9083686360121195,-0.9083686360121195,0.076154426,0.026708199,0.0002846321,0.19487736,0.00474438,1.0
100000,0.35822082,40.16112956810631,9.0,-0.73189867,-0.9114522737215168,-0.9114522737215168,0.017172169,0.025152212,0.00025695981,0.1856533,0.0042840983,1.0
150000,0.20489725,99.22869022869023,18.0,-0.6022587,-0.8212499895133079,-0.8212499895133079,0.01607742,0.028004777,0.00022615408,0.17538472,0.003771695,1.0
200000,0.111210406,321.05442176870747,32.0,-0.3690617,-0.35675673589513107,-0.35675673589513107,0.012085733,0.02401169,0.00019531566,0.16510521,0.0032587494,1.0
250000,0.07071061,744.3225806451613,114.0,-0.16185585,0.4387097156816913,0.4387097156816913,0.005014834,0.026898598,0.00016450314,0.15483436,0.0027462344,1.0
300000,0.065402105,1373.1739130434783,198.0,-0.025841998,1.7826087640031525,1.7826087640031525,0.0043819873,0.023680521,0.00013371126,0.1445704,0.0022340626,1.0
350000,0.07104808,2153.7894736842104,282.0,0.05308823,3.40000009458316,3.40000009458316,0.00383087,0.02125347,0.000102899,0.13429964,0.0017215519,1.0
400000,0.06264531,2414.875,370.0,0.110252455,3.9937501079402864,3.9937501079402864,0.0038205888,0.025017496,7.515413e-05,0.12505135,0.0012600623,1.0
450000,0.061414354,1336.1739130434783,456.0,0.14082594,1.7130435507582582,1.7130435507582582,0.0045918603,0.026011527,4.7445807e-05,0.115815245,0.0007991805,1.0
500000,0.062134404,2386.846153846154,540.0,0.14987245,3.88461548777727,3.88461548777727,0.0031958073,0.024197578,1.661842e-05,0.10553944,0.0002864181,1.0
